{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20_newsgroups.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoMB8oaqLIMWX5vz4CkzjL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agusrichard/data-science-projects/blob/master/News%20Groups/20_newsgroups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV38MQurmS0Q",
        "colab_type": "text"
      },
      "source": [
        "# Predictive Modeling: 20 Newsgroups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQFpY9_4nkSt",
        "colab_type": "text"
      },
      "source": [
        "__Import Libraries__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWc8AnEnnmFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f08447e7-e93b-4d28-b965-116730b49651"
      },
      "source": [
        "# Essentials\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning Estimator\n",
        "\n",
        "\n",
        "# Machine Learning Utilities\n",
        "\n",
        "\n",
        "# Deep Learning\n",
        "\n",
        "\n",
        "# Fetch data from sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n",
        "# Ignore warning\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqBsq0HPNkQ9",
        "colab_type": "text"
      },
      "source": [
        "__Helper function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPeHdT-xNmtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_none(ls):\n",
        "    \"\"\"\n",
        "    Check is there any NoneType element inside a list\n",
        "    \"\"\"\n",
        "    num_none = 0\n",
        "    for element in ls:\n",
        "        if element is None:\n",
        "            num_none += 1\n",
        "    return num_none\n",
        "\n",
        "\n",
        "def cleaning_text(text):\n",
        "    \"\"\"\n",
        "    Cleaning each text with custom specification using Regular Expression\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        Text to clean\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    Cleaned text\n",
        "    \"\"\"\n",
        "\n",
        "    splitted = text.split('\\n')\n",
        "    email_pattern = re.compile(r\"\\S+@\\S+\")      \n",
        "    special_chars_pattern = re.compile(r\"[^\\w\\s'\\\"_]\")\n",
        "    space_pattern = re.compile(r\"[\\s]{1,}\")\n",
        "    num_pattern = re.compile(r\"\\d+\")\n",
        "\n",
        "    for i in range(len(splitted)):\n",
        "\n",
        "        # Replace the sentence which startswith From, Subject, In-Reply-To, Organization, Lines (header)\n",
        "        # with single white space\n",
        "        if splitted[i].startswith('From:') or splitted[i].startswith('Subject:') or \\\n",
        "                splitted[i].startswith('In-Reply-To') or splitted[i].startswith('Organization:') or \\\n",
        "                splitted[i].startswith('Lines:') or splitted[i].startswith('Originator:') or \\\n",
        "                splitted[i].startswith('Nntp-Posting-Host:') or splitted[i].startswith('Distribution:'):\n",
        "            splitted[i] = ' '\n",
        "\n",
        "        # if the sentence contains email, it will be replaced with single white space\n",
        "        splitted[i] = email_pattern.sub('', splitted[i])\n",
        "\n",
        "        # Removing some special characters\n",
        "        splitted[i] = special_chars_pattern.sub('', splitted[i])\n",
        "\n",
        "        # If more than one white space between words, replace it with single white space\n",
        "        splitted[i] = space_pattern.sub(' ', splitted[i])\n",
        "\n",
        "        # Removing numbers\n",
        "        splitted[i] = num_pattern.sub('', splitted[i])\n",
        "    \n",
        "    return ' '.join(splitted).strip()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN4GJ18ZoQzT",
        "colab_type": "text"
      },
      "source": [
        "__Load the data__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5WagmCroSyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bunch_train = fetch_20newsgroups(subset='train')\n",
        "bunch_test = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzy7WNIHsMRA",
        "colab_type": "text"
      },
      "source": [
        "See what kind of keys available in bunch object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7J78xUasqow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23cd5b97-f2da-493b-bb9e-08982246664b"
      },
      "source": [
        "bunch_train.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJephh84sufo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c77f4a7-023f-4084-9ee4-88e972173dfc"
      },
      "source": [
        "print(bunch_train['DESCR'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _20newsgroups_dataset:\n",
            "\n",
            "The 20 newsgroups text dataset\n",
            "------------------------------\n",
            "\n",
            "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
            "20 topics split in two subsets: one for training (or development)\n",
            "and the other one for testing (or for performance evaluation). The split\n",
            "between the train and test set is based upon a messages posted before\n",
            "and after a specific date.\n",
            "\n",
            "This module contains two loaders. The first one,\n",
            ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
            "returns a list of the raw texts that can be fed to text feature\n",
            "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
            "with custom parameters so as to extract feature vectors.\n",
            "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
            "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
            "extractor.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   ==========\n",
            "    Classes                     20\n",
            "    Samples total            18846\n",
            "    Dimensionality               1\n",
            "    Features                  text\n",
            "    =================   ==========\n",
            "\n",
            "Usage\n",
            "~~~~~\n",
            "\n",
            "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
            "fetching / caching functions that downloads the data archive from\n",
            "the original `20 newsgroups website`_, extracts the archive contents\n",
            "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
            ":func:`sklearn.datasets.load_files` on either the training or\n",
            "testing set folder, or both of them::\n",
            "\n",
            "  >>> from sklearn.datasets import fetch_20newsgroups\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
            "\n",
            "  >>> from pprint import pprint\n",
            "  >>> pprint(list(newsgroups_train.target_names))\n",
            "  ['alt.atheism',\n",
            "   'comp.graphics',\n",
            "   'comp.os.ms-windows.misc',\n",
            "   'comp.sys.ibm.pc.hardware',\n",
            "   'comp.sys.mac.hardware',\n",
            "   'comp.windows.x',\n",
            "   'misc.forsale',\n",
            "   'rec.autos',\n",
            "   'rec.motorcycles',\n",
            "   'rec.sport.baseball',\n",
            "   'rec.sport.hockey',\n",
            "   'sci.crypt',\n",
            "   'sci.electronics',\n",
            "   'sci.med',\n",
            "   'sci.space',\n",
            "   'soc.religion.christian',\n",
            "   'talk.politics.guns',\n",
            "   'talk.politics.mideast',\n",
            "   'talk.politics.misc',\n",
            "   'talk.religion.misc']\n",
            "\n",
            "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
            "attribute is the integer index of the category::\n",
            "\n",
            "  >>> newsgroups_train.filenames.shape\n",
            "  (11314,)\n",
            "  >>> newsgroups_train.target.shape\n",
            "  (11314,)\n",
            "  >>> newsgroups_train.target[:10]\n",
            "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
            "\n",
            "It is possible to load only a sub-selection of the categories by passing the\n",
            "list of the categories to load to the\n",
            ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
            "\n",
            "  >>> cats = ['alt.atheism', 'sci.space']\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
            "\n",
            "  >>> list(newsgroups_train.target_names)\n",
            "  ['alt.atheism', 'sci.space']\n",
            "  >>> newsgroups_train.filenames.shape\n",
            "  (1073,)\n",
            "  >>> newsgroups_train.target.shape\n",
            "  (1073,)\n",
            "  >>> newsgroups_train.target[:10]\n",
            "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "\n",
            "Converting text to vectors\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "In order to feed predictive or clustering models with the text data,\n",
            "one first need to turn the text into vectors of numerical values suitable\n",
            "for statistical analysis. This can be achieved with the utilities of the\n",
            "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
            "example that extract `TF-IDF`_ vectors of unigram tokens\n",
            "from a subset of 20news::\n",
            "\n",
            "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
            "  ...               'comp.graphics', 'sci.space']\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
            "  ...                                       categories=categories)\n",
            "  >>> vectorizer = TfidfVectorizer()\n",
            "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
            "  >>> vectors.shape\n",
            "  (2034, 34118)\n",
            "\n",
            "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
            "components by sample in a more than 30000-dimensional space\n",
            "(less than .5% non-zero features)::\n",
            "\n",
            "  >>> vectors.nnz / float(vectors.shape[0])\n",
            "  159.01327...\n",
            "\n",
            ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
            "returns ready-to-use token counts features instead of file names.\n",
            "\n",
            ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
            ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
            "\n",
            "\n",
            "Filtering text for more realistic training\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "It is easy for a classifier to overfit on particular things that appear in the\n",
            "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
            "high F-scores, but their results would not generalize to other documents that\n",
            "aren't from this window of time.\n",
            "\n",
            "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
            "which is fast to train and achieves a decent F-score::\n",
            "\n",
            "  >>> from sklearn.naive_bayes import MultinomialNB\n",
            "  >>> from sklearn import metrics\n",
            "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
            "  ...                                      categories=categories)\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> clf = MultinomialNB(alpha=.01)\n",
            "  >>> clf.fit(vectors, newsgroups_train.target)\n",
            "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
            "  0.88213...\n",
            "\n",
            "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
            "the training and test data, instead of segmenting by time, and in that case\n",
            "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
            "yet of what's going on inside this classifier?)\n",
            "\n",
            "Let's take a look at what the most informative features are:\n",
            "\n",
            "  >>> import numpy as np\n",
            "  >>> def show_top10(classifier, vectorizer, categories):\n",
            "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
            "  ...     for i, category in enumerate(categories):\n",
            "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
            "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
            "  ...\n",
            "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
            "  alt.atheism: edu it and in you that is of to the\n",
            "  comp.graphics: edu in graphics it is for and of to the\n",
            "  sci.space: edu it that is in and space to of the\n",
            "  talk.religion.misc: not it you in is that and to of the\n",
            "\n",
            "\n",
            "You can now see many things that these features have overfit to:\n",
            "\n",
            "- Almost every group is distinguished by whether headers such as\n",
            "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
            "- Another significant feature involves whether the sender is affiliated with\n",
            "  a university, as indicated either by their headers or their signature.\n",
            "- The word \"article\" is a significant feature, based on how often people quote\n",
            "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
            "  wrote:\"\n",
            "- Other features match the names and e-mail addresses of particular people who\n",
            "  were posting at the time.\n",
            "\n",
            "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
            "barely have to identify topics from text at all, and they all perform at the\n",
            "same high level.\n",
            "\n",
            "For this reason, the functions that load 20 Newsgroups data provide a\n",
            "parameter called **remove**, telling it what kinds of information to strip out\n",
            "of each file. **remove** should be a tuple containing any subset of\n",
            "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
            "blocks, and quotation blocks respectively.\n",
            "\n",
            "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
            "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
            "  ...                                      categories=categories)\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
            "  0.77310...\n",
            "\n",
            "This classifier lost over a lot of its F-score, just because we removed\n",
            "metadata that has little to do with topic classification.\n",
            "It loses even more if we also strip this metadata from the training data:\n",
            "\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
            "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
            "  ...                                       categories=categories)\n",
            "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
            "  >>> clf = MultinomialNB(alpha=.01)\n",
            "  >>> clf.fit(vectors, newsgroups_train.target)\n",
            "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
            "  0.76995...\n",
            "\n",
            "Some other classifiers cope better with this harder version of the task. Try\n",
            "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
            "the ``--filter`` option to compare the results.\n",
            "\n",
            ".. topic:: Recommendation\n",
            "\n",
            "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
            "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
            "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
            "  lower because it is more realistic.\n",
            "\n",
            ".. topic:: Examples\n",
            "\n",
            "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
            "\n",
            "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml1-MWlgsx3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1641fc0c-dd12-424a-c3a7-85defefc4549"
      },
      "source": [
        "# How many data points in training set and test set\n",
        "print(f'Number of data points in training set: {len(bunch_train.target)}')\n",
        "print(f'Number of data points in test set: {len(bunch_test.target)}')\n",
        "print(f'Total data points: {len(bunch_train.target) + len(bunch_test.target)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points in training set: 11314\n",
            "Number of data points in test set: 7532\n",
            "Total data points: 18846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K_8QjSEuXYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c4eb8ea5-48f2-46ea-c8e3-84f7ed0c9624"
      },
      "source": [
        "# Target names \n",
        "bunch_train.target_names"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPuS1LnNvQDT",
        "colab_type": "text"
      },
      "source": [
        "Let's check one of the data point in training set, what it looks like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd6TKfU6vWjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7926b2e4-7b14-4b5e-8f0e-595ead05ce37"
      },
      "source": [
        "print(bunch_train.data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2k7DmcNvaM9",
        "colab_type": "text"
      },
      "source": [
        "If we see the above text, what it will be classified to? Some text which talked about car or automotive seems pretty reasonable. But what is it actually?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gice8YHnv7pW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d854f03a-ea3d-4a20-c9ff-2cd7f6cb43e9"
      },
      "source": [
        "print(bunch_train.target_names[bunch_train.target[0]])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rec.autos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NItqJcqRv-cx",
        "colab_type": "text"
      },
      "source": [
        "The main purpose of this notebook is to classify newsgroups into one of the twenty possible options. It could be 'rec.autos' which certainly talked about automotive, it could be 'sci.space', or another. Let's start with preliminary step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQvPYwTUxA1g",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOamZPhhw-aO",
        "colab_type": "text"
      },
      "source": [
        "## Preliminary Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duDGhF4QxANc",
        "colab_type": "text"
      },
      "source": [
        "In the preliminary step, we will evaluate our data. Is it contain null values? Or anything suspicious that will make our model less predictive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ_wovtyyIwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05ff2e51-c5ba-4245-8c2d-af5f432428b8"
      },
      "source": [
        "# any missing values in target vector (training and test)\n",
        "print('Any missing values in training target vector:', np.isnan(bunch_train.target).sum())\n",
        "print('Any missing values in test target vector: ', np.isnan(bunch_test.target).sum())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Any missing values in training target vector: 0\n",
            "Any missing values in test target vector:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0-BAI4oMpsj",
        "colab_type": "text"
      },
      "source": [
        "No missing values in target vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2w8JZ4eNV1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3d76935-9325-49a6-c877-03e3b9922642"
      },
      "source": [
        "# any missing value in feature data (training and test)\n",
        "print('Any missing values in training feature data:', check_none(bunch_train.data))\n",
        "print('Any missing values in test feature data:', check_none(bunch_test.data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Any missing values in training feature data: 0\n",
            "Any missing values in test feature data: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdToIADgOF7z",
        "colab_type": "text"
      },
      "source": [
        "Also no missing values in feature data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he9J2nRPOJd-",
        "colab_type": "text"
      },
      "source": [
        "Now, to become more convenience we put feature data (training and test set) also target vector into their own variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dzUuvzlOj6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = bunch_train.data\n",
        "test_data = bunch_test.data\n",
        "train_target = bunch_train.target\n",
        "test_target = bunch_test.target"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMHmnc29O0c-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a550c0cd-b415-437d-fa30-e4e5c5b60097"
      },
      "source": [
        "# Look at 100th data point in feature data\n",
        "print(train_data[99])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: tmc@spartan.ac.BrockU.CA (Tim Ciceran)\n",
            "Subject: Re: Hijaak\n",
            "Organization: Brock University, St. Catharines Ontario\n",
            "X-Newsreader: TIN [version 1.1 PL9]\n",
            "Lines: 15\n",
            "\n",
            "Haston, Donald Wayne (haston@utkvx.utk.edu) wrote:\n",
            ": Currently, I use a shareware program called Graphics Workshop.\n",
            ": What kinds of things will Hijaak do that these shareware programs\n",
            ": will not do?\n",
            "\n",
            "I also use Graphic Workshop and the only differences that I know of are that\n",
            "Hijaak has screen capture capabilities and acn convert to/from a couple of\n",
            "more file formats (don't know specifically which one).  In the April 13\n",
            "issue of PC Magazine they test the twelve best selling image capture/convert\n",
            "utilities, including Hijaak.\n",
            "\n",
            "TMC.\n",
            "(tmc@spartan.ac.brocku.ca)\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMpipkOO_t3",
        "colab_type": "text"
      },
      "source": [
        "As we can see, our data composed by header and footer, which would not be beneficial or probably make our model tend to overfit. This time, we will remove it manually. (Actually, we can set arguments in \"fetch_20newsgroups\" function to exclude headers, footers and quotes, but for learning purpose, we will do it manually)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkcQxtwjUwHW",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwSQ12HzUwc6",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvcp_9lh5fyg",
        "colab_type": "text"
      },
      "source": [
        "In the section helper function above, we have defined a function to clean our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jxGIwoC5m0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_cleaned = []\n",
        "for element in train_data:\n",
        "    train_data_cleaned.append(cleaning_text(element))\n",
        "\n",
        "test_data_cleaned = []\n",
        "for element in test_data:\n",
        "    test_data_cleaned.append(cleaning_text(element))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0IO5iz6sBb",
        "colab_type": "text"
      },
      "source": [
        "__Comparing uncleaned and cleaned data__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ3I4quw6NUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "48b7cb1d-3f7f-4403-8f85-e3dcb1644624"
      },
      "source": [
        "# original data\n",
        "print(train_data[2109])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: jvigneau@cs.ulowell.edu (Joe Vigneau)\n",
            "Subject: Re: [soc.motss, et al.] \"Princeton axes matching funds for Boy Scouts\"\n",
            "In-Reply-To: bevans@carina.unm.edu's message of 4 Apr 1993 12:19:20 GMT\n",
            "Organization: -\n",
            "\t<1993Apr3.214557.24073@midway.uchicago.edu> <1pmjo8INN2l0@lynx.unm.edu>\n",
            "Lines: 21\n",
            "\n",
            "In article <1pmjo8INN2l0@lynx.unm.edu> bevans@carina.unm.edu (Mathemagician) writes:\n",
            "\n",
            "   Just what do gay people do that straight people don't?\n",
            "\n",
            "Absolutely nothing.\n",
            "\n",
            "I'm a VERY straight(as an arrow), 17-year old male that is involved in the BSA.\n",
            "\n",
            "I don't care what gay people do among each other, as long as they don't make\n",
            "passes at me or anything.  At my summer camp where I work, my boss is gay.\n",
            "Not in a 'pansy' way of gay (I know a few), but just 'one of the guys'.\n",
            "He doesn't push anything on me, and we give him the same respect back, due\n",
            "to his position.\n",
            "\n",
            "If anything, the BSA has taught me, I don't know, tolerance or something.\n",
            "Before I met this guy, I thought all gays were 'faries'.  So, the BSA HAS\n",
            "taught me to be an antibigot.\n",
            "\n",
            "Basically, It comes down to this: What you do among yourself is your own\n",
            "business. No one else has the right to tell you otherwise, unless it\n",
            "violates someone else's civil rights.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJTpK6YK6gHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "95deae6b-56a5-4a1e-81fa-89111eaf14f1"
      },
      "source": [
        "# cleaned data\n",
        "print(train_data_cleaned[2109])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In article Mathemagician writes   Just what do gay people do that straight people don't  Absolutely nothing  I'm a VERY straightas an arrow year old male that is involved in the BSA  I don't care what gay people do among each other as long as they don't make passes at me or anything At my summer camp where I work my boss is gay Not in a 'pansy' way of gay I know a few but just 'one of the guys' He doesn't push anything on me and we give him the same respect back due to his position  If anything the BSA has taught me I don't know tolerance or something Before I met this guy I thought all gays were 'faries' So the BSA HAS taught me to be an antibigot  Basically It comes down to this What you do among yourself is your own business No one else has the right to tell you otherwise unless it violates someone else's civil rights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a3Uu0BD69j4",
        "colab_type": "text"
      },
      "source": [
        "Note that we have removed email address, special characters, headers, and numbers. Which probably will impacting our model performance, in the end of this notebook, we will compare whether cleaning the data really improve the performance or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn-frw_E7e8M",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERSK-SQh7kJH",
        "colab_type": "text"
      },
      "source": [
        "## Text Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkd_dBJ7nxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}