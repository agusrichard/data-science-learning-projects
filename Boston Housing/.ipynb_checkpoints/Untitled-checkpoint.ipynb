{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling: Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the essential modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Ml Algorithms \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "import xgboost\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look on first five of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     15.2  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this dataset, we have categorical features which are 'chas' and 'rad', but 'chas' is already in the correct form, and we have to change column 'rad' to make our model more robust. Also rearrange the columns to make it more cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, pd.get_dummies(dataset['rad'], prefix='rad')], axis=1).drop('rad', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['ID', 'crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'tax',\n",
    "       'ptratio', 'black', 'lstat', 'rad_1', 'rad_2', 'rad_3', 'rad_4',\n",
    "       'rad_5', 'rad_6', 'rad_7', 'rad_8', 'rad_24', 'medv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'tax',\n",
       "       'ptratio', 'black', 'lstat', 'rad_1', 'rad_2', 'rad_3', 'rad_4',\n",
       "       'rad_5', 'rad_6', 'rad_7', 'rad_8', 'rad_24', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see that column 'rad' has gone, and new dummies features from rad have been added to our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the feature matrix and target vector, and convert it to numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values # we dont take column ID and medv (the target vector)\n",
    "y = dataset.iloc[:, -1].values # the target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
      " 4.090e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use the machine learning algorithms. In this notebook, we will try every common Machine Learning Algorithms and look at its score with cross_val_score function. We will look for the best hyperparameter with greedy algorithm of GridSearchCV class, and at the end we split the data into training set and validation set, then look at the performance on validation set by training it first on train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use KNeighborsRegressor. Note that this algorithm needs scaling first. But, for learning purposes we will try it without scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor cross val score (default & no scaling): [-1.27743668e+00  1.26213407e-01 -5.08365911e-01 -1.12486164e-04\n",
      " -1.59147857e+00]\n",
      "The mean score: -0.650\n"
     ]
    }
   ],
   "source": [
    "cvs_knn_default_no_scaling_score = cross_val_score(KNeighborsRegressor(), X, y, cv=5, scoring='r2') # no scaling and using default hyperparameter\n",
    "print(\"KNeighborsRegressor cross val score (default & no scaling): {}\".format(cvs_knn_default_no_scaling_score))\n",
    "print(\"The mean score: {:.3f}\".format(cvs_knn_default_no_scaling_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its R2 score is negative, so horrible. Now let's see what happen if we scale it with StandardScaler and still use the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor cross val score (default & scaled): [-0.22459519  0.49962429 -0.1921519   0.22944539 -0.23294058]\n",
      "The mean score: 0.016\n"
     ]
    }
   ],
   "source": [
    "cvs_knn_default_score = cross_val_score(pipe_knn, X, y, cv=5, scoring='r2')\n",
    "print(\"KNeighborsRegressor cross val score (default & scaled): {}\".format(cvs_knn_default_score))\n",
    "print(\"The mean score: {:.3f}\".format(cvs_knn_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still aweful. Let's find the best hyperparameters with GridSearch. In here, we will only use two hyperparameters: n_neighbors and distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'knn__weights' : ['distance', 'uniform'],\n",
    "    'knn__n_neighbors' : list(range(2, 21)) # we test n_neighbors parameter from 2 to 20\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(pipe_knn, param_grid=param_grid, cv=5, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05875229208958241"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 20, 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_knn__weights  param_knn__n_neighbors\n",
       "distance            2                        -0.031728\n",
       "                    3                         0.038893\n",
       "                    4                         0.038841\n",
       "                    5                         0.037972\n",
       "                    6                        -0.010672\n",
       "                    7                        -0.055296\n",
       "                    8                        -0.042408\n",
       "                    9                        -0.052224\n",
       "                    10                       -0.032289\n",
       "                    11                       -0.013722\n",
       "                    12                        0.008872\n",
       "                    13                        0.037274\n",
       "                    14                        0.039667\n",
       "                    15                        0.014169\n",
       "                    16                        0.026639\n",
       "                    17                        0.033953\n",
       "                    18                        0.037984\n",
       "                    19                        0.049972\n",
       "                    20                        0.052627\n",
       "uniform             2                        -0.023914\n",
       "                    3                         0.034613\n",
       "                    4                         0.018759\n",
       "                    5                         0.015982\n",
       "                    6                        -0.052449\n",
       "                    7                        -0.110079\n",
       "                    8                        -0.091795\n",
       "                    9                        -0.101937\n",
       "                    10                       -0.073743\n",
       "                    11                       -0.033867\n",
       "                    12                        0.003319\n",
       "                    13                        0.045692\n",
       "                    14                        0.051428\n",
       "                    15                        0.022466\n",
       "                    16                        0.036721\n",
       "                    17                        0.044617\n",
       "                    18                        0.042573\n",
       "                    19                        0.057283\n",
       "                    20                        0.058752\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn_results = pd.DataFrame(grid_knn.cv_results_)\n",
    "grid_knn_results.groupby(['param_knn__weights', 'param_knn__n_neighbors']).mean()['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result we get is pretty bad. Let's move to other model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that stochastic algorithms are need scaleddata to have better performance. For learning purposes we dont scale the data and use default hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor cross val score (default & no scaling): [-4.92025341e+27 -1.16251318e+27 -6.13110029e+26 -2.43449545e+27\n",
      " -9.68773822e+27]\n",
      "The mean score: -3763622057763393428187512832.000\n"
     ]
    }
   ],
   "source": [
    "sgd_default_no_scaling_score = cross_val_score(SGDRegressor(), X, y, cv=5, scoring='r2') # no scaling and using default hyperparameter\n",
    "print(\"SGDRegressor cross val score (default & no scaling): {}\".format(sgd_default_no_scaling_score))\n",
    "print(\"The mean score: {:.3f}\".format(sgd_default_no_scaling_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its R2 score is negative. Certainly we need to scale it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sgd = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd', SGDRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor cross val score (default & no scaling): [ 0.72137527  0.64710453  0.33841331 -0.0245005  -1.24371964]\n",
      "The mean score: 0.088\n"
     ]
    }
   ],
   "source": [
    "sgd_default_score = cross_val_score(pipe_sgd, X, y, cv=5, scoring='r2') # no scaling and using default hyperparameter\n",
    "print(\"SGDRegressor cross val score (default & no scaling): {}\".format(sgd_default_score))\n",
    "print(\"The mean score: {:.3f}\".format(sgd_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See... R2 score is increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several hyperparameters for SGD such as penalty, alpha, eta0, l1_ratio, early_stopping, loss, etc. But we will use three: penalty, alpha, eta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'sgd__penalty' : ['l1', 'l2', 'elasticnet'], # regularization penalty\n",
    "    'sgd__alpha' : [0.001, 0.01, 0.1, 1, 10, 100, 1000], # regularization parameter\n",
    "    'sgd__eta0' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_sgd = GridSearchCV(pipe_sgd, param_grid=param_grid, cv=3, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33060266278252504"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sgd.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sgd__alpha': 1, 'sgd__eta0': 0.1, 'sgd__penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sgd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.470000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.993321e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.778627e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.608618e+30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.550897e+26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-7.291658e+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-9.594631e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.306027e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  1.470000e+02\n",
       "mean  -3.993321e+28\n",
       "std    1.778627e+29\n",
       "min   -1.608618e+30\n",
       "25%   -7.550897e+26\n",
       "50%   -7.291658e+22\n",
       "75%   -9.594631e-01\n",
       "max    3.306027e-01"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_sgd.cv_results_['mean_test_score']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the standard deviation of the mean test score, quite dispersed right? Because stochastic algorithm uses randomness, if we run it several times, the score will change at each run. But the best score we have is 0.27 (note that if i run it again, probably it will change), which is better than KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the more popular ML algorithm in linear model family (as i know). This model is simple, no need to scale (but we will try to scale it to see are there any differences) and no need for hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression cross val score (no scaling): [ 0.45163553  0.39253457 -2.65804985]\n",
      "The mean score: -0.605\n"
     ]
    }
   ],
   "source": [
    "linreg_no_scaling_score = cross_val_score(LinearRegression(), X, y, cv=3, scoring='r2') # no scaling and using default hyperparameter\n",
    "print(\"Linear Regression cross val score (no scaling): {}\".format(linreg_no_scaling_score))\n",
    "print(\"The mean score: {:.3f}\".format(linreg_no_scaling_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linreg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linreg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression cross val score (no scaling): [ 0.44696893  0.40233584 -2.73421918]\n",
      "The mean score: -0.628\n"
     ]
    }
   ],
   "source": [
    "linreg_score = cross_val_score(pipe_linreg, X, y, cv=3, scoring='r2') # no scaling and using default hyperparameter\n",
    "print(\"Linear Regression cross val score (no scaling): {}\".format(linreg_score))\n",
    "print(\"The mean score: {:.3f}\".format(linreg_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so different without scaling right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happen if we use PolynomialFeatures to expand the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression cross val score (with Polynomial terms): [ -11635.10957162   -3398.25411481 -162062.65521929]\n",
      "The mean score: -59032.006\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "linreg_poly_score = cross_val_score(LinearRegression(), poly.fit_transform(X), y, scoring='r2')\n",
    "print(\"Linear Regression cross val score (with Polynomial terms): {}\".format(linreg_poly_score))\n",
    "print(\"The mean score: {:.3f}\".format(linreg_poly_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly adding more features does not help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, we won't scale the data first. Let's begin with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression cross val score (default): [ 0.56288541  0.35648953 -1.17868545]\n",
      "The mean score: -0.09\n"
     ]
    }
   ],
   "source": [
    "ridge_default_score = cross_val_score(Ridge(), X, y, cv=3, scoring='r2')\n",
    "print('Ridge Regression cross val score (default): {}'.format(ridge_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(ridge_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the feature matrix with expanded features (due to PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression cross val score (default and with polynomial terms): [  -50.09180674    -6.08025845 -1703.31683783]\n",
      "The mean score: -586.50\n"
     ]
    }
   ],
   "source": [
    "ridge_poly_default_score = cross_val_score(Ridge(), poly.fit_transform(X), y, cv=3, scoring='r2')\n",
    "print('Ridge Regression cross val score (default and with polynomial terms): {}'.format(ridge_poly_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(ridge_poly_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use GridSearch to find the best parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_ridge = GridSearchCV(Ridge(), param_grid=param_grid, cv=3, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3120057313941854"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.602560\n",
       "1   -0.584480\n",
       "2   -0.444172\n",
       "3   -0.086437\n",
       "4    0.131436\n",
       "5    0.312006\n",
       "6    0.161435\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_ridge.cv_results_)['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we move to Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression corss val score (default): [ 0.49013108  0.04916419 -0.01947876]\n",
      "The mean score: 0.17\n"
     ]
    }
   ],
   "source": [
    "lasso_default_score = cross_val_score(Lasso(), X, y, cv=3, scoring='r2')\n",
    "print('Lasso Regression corss val score (default): {}'.format(lasso_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(lasso_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't expande the features, because probably our dataset is already has irrelevant features. We will see later. Let's use GridSearch to find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_lasso = GridSearchCV(Lasso(), param_grid=param_grid, cv=3, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17327216889423158"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lasso.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.586315\n",
       "1   -0.239002\n",
       "2    0.010592\n",
       "3    0.173272\n",
       "4    0.068983\n",
       "5   -0.489925\n",
       "6   -0.695293\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_lasso.cv_results_)['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the difference between Ridge and Lasso is the way they regularize the model. Ridge will make each feature has little influence, instead Lasso will actually ignore some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet is using the combination of the regularization power of Ridge and Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet cross val score (default): [ 0.49295924  0.10315915 -0.03631311]\n",
      "The mean score: 0.19\n"
     ]
    }
   ],
   "source": [
    "elasticnet_default_score = cross_val_score(ElasticNet(), X, y, cv=3, scoring='r2')\n",
    "print('ElasticNet cross val score (default): {}'.format(elasticnet_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(elasticnet_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use GridSearch to find the best parameters, in here we will use alpha and l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'l1_ratio' : [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_elasticnet = GridSearchCV(ElasticNet(), param_grid=param_grid, cv=3, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.265582850154267"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_elasticnet.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'l1_ratio': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_elasticnet.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_alpha', 'param_l1_ratio', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'mean_train_score',\n",
       "       'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_elasticnet.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_alpha\n",
       "0.001      -0.436813\n",
       "0.010      -0.074493\n",
       "0.100       0.154940\n",
       "1.000       0.197544\n",
       "10.000      0.071101\n",
       "100.000    -0.416145\n",
       "1000.000   -0.688539\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_elasticnet.cv_results_).groupby('param_alpha')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_l1_ratio\n",
       "0.0   -0.046273\n",
       "0.1   -0.083719\n",
       "0.2   -0.144526\n",
       "0.3   -0.167523\n",
       "0.4   -0.178143\n",
       "0.5   -0.184231\n",
       "0.6   -0.189489\n",
       "0.7   -0.197203\n",
       "0.8   -0.208242\n",
       "0.9   -0.223333\n",
       "1.0   -0.251098\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_elasticnet.cv_results_).groupby('param_l1_ratio')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the best parameter l1_ratio = 0, which means the penalty is l2. So it supposedly the same as using Ridge, and the best parameter for alpha is 0, surely different from the result we have when using Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use LinearSVR which is more complex than LinearRegression or any other linear model. Note that when using SVMs algorithms we need to scale the data first to have better result. But as usual we don't use it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR cross val score (default and no scaling): [ 0.13141627  0.60156649  0.44327683 -0.08346035 -0.78312707]\n",
      "The mean score: 0.06\n"
     ]
    }
   ],
   "source": [
    "linsvr_default_no_scaling_score = cross_val_score(LinearSVR(), X, y, cv=5, scoring='r2')\n",
    "print('LinearSVR cross val score (default and no scaling): {}'.format(linsvr_default_no_scaling_score))\n",
    "print(\"The mean score: {:.2f}\".format(linsvr_default_no_scaling_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the scaled data. Using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linsvr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linsvr', LinearSVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR cross val score (default and no scaling): [ 0.56750153  0.68509431  0.23411804  0.03962725 -0.54107938]\n",
      "The mean score: 0.20\n"
     ]
    }
   ],
   "source": [
    "linsvr_default_score = cross_val_score(pipe_linsvr, X, y, cv=5, scoring='r2')\n",
    "print('LinearSVR cross val score (default): {}'.format(linsvr_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(linsvr_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's searching time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'linsvr__epsilon' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'linsvr__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_linsvr = GridSearchCV(pipe_linsvr, param_grid=param_grid, cv=5, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19984402892461908"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_linsvr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linsvr__C': 1, 'linsvr__epsilon': 0.001}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_linsvr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_linsvr__epsilon\n",
       "0.001       -2.587513\n",
       "0.010       -2.699267\n",
       "0.100       -2.656507\n",
       "1.000       -2.702798\n",
       "10.000      -3.525321\n",
       "100.000    -10.727343\n",
       "1000.000   -10.727343\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_linsvr.cv_results_).groupby('param_linsvr__epsilon')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_linsvr__C\n",
       "0.001      -10.539883\n",
       "0.010       -8.973172\n",
       "0.100       -3.190656\n",
       "1.000       -3.038791\n",
       "10.000      -3.098147\n",
       "100.000     -3.137211\n",
       "1000.000    -3.648232\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_linsvr.cv_results_).groupby('param_linsvr__C')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that kernel trick that LinearSVR using is linear. Now, we use SVR, which the more general model, it means that we can tweak which kernel trick we want to use. Same as LinearSVR, this model will perform better with scaled data, so scaling is neccessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR cross val score (default and no scaling): [-0.0327477  -0.05107432 -1.42701088  0.01562126 -2.2448059 ]\n",
      "The mean score: -0.75\n"
     ]
    }
   ],
   "source": [
    "svr_default_no_scaling_score = cross_val_score(SVR(), X, y, cv=5, scoring='r2')\n",
    "print('SVR cross val score (default and no scaling): {}'.format(svr_default_no_scaling_score))\n",
    "print(\"The mean score: {:.2f}\".format(svr_default_no_scaling_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR cross val score (default): [ 0.4124707   0.40408661 -0.6261605   0.25580055 -1.34137876]\n",
      "The mean score: -0.18\n"
     ]
    }
   ],
   "source": [
    "svr_default_score = cross_val_score(pipe_svr, X, y, cv=5, scoring='r2')\n",
    "print('SVR cross val score (default): {}'.format(svr_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(svr_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's searching time. We will rbf kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'svr__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'svr__gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "grid_svr = GridSearchCV(pipe_svr, param_grid=param_grid, cv=5, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.341379212579757"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': 1000, 'svr__gamma': 0.001}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_svr__C\n",
       "0.001      -0.768252\n",
       "0.010      -0.767493\n",
       "0.100      -0.760642\n",
       "1.000      -0.709444\n",
       "10.000     -0.639138\n",
       "100.000    -0.814071\n",
       "1000.000   -0.954943\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_svr.cv_results_).groupby('param_svr__C')['mean_test_score'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_svr__gamma\n",
       "0.001      -0.325278\n",
       "0.010      -0.297308\n",
       "0.100      -0.753644\n",
       "1.000      -0.742281\n",
       "10.000     -0.772604\n",
       "100.000    -0.772698\n",
       "1000.000   -0.772698\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_svr.cv_results_).groupby('param_svr__gamma')['mean_test_score'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use ensemble ML algorithms, the first one is RandomForestRegressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor cross val score (default): [ 0.67294     0.84227784  0.75384568  0.49261092 -0.12311533]\n",
      "The mean score: 0.53\n"
     ]
    }
   ],
   "source": [
    "rf_default_score = cross_val_score(RandomForestRegressor(), X, y, cv=5, scoring='r2')\n",
    "print('RandomForestRegressor cross val score (default): {}'.format(rf_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(rf_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will look for the best parameters for RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth' : list(range(2, 11)),\n",
    "    'max_features' : list(range(3, 24, 3)) \n",
    "}\n",
    "\n",
    "grid_rf = RandomizedSearchCV(RandomForestRegressor(), param_grid=param_grid, cv=5, scoring='r2').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5830035779990217"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'max_features': 15, 'n_estimators': 100}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38328332,  0.64878332,  0.26642751,  0.23414977, -0.318297  ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestRegressor(n_estimators=250, max_depth=3, max_features=3), X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientDescentRegressor cross val score (default): [0.73370407 0.86294788 0.74353686 0.41000636 0.22397996]\n",
      "The mean score: 0.59\n"
     ]
    }
   ],
   "source": [
    "gbrt_default_score = cross_val_score(GradientBoostingRegressor(), X, y, cv=5, scoring='r2')\n",
    "print('GradientDescentRegressor cross val score (default): {}'.format(gbrt_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(gbrt_default_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search the best parameters, we will use RandomizedSearchCV, to make the process faster, which probably make the true best parameters get missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth' : list(range(2, 11)),\n",
    "    'max_features' : list(range(3, 22))\n",
    "}\n",
    "\n",
    "grid_gbrt = RandomizedSearchCV(GradientBoostingRegressor(), param_distributions=param_grid, cv=5, scoring='r2', n_iter=15, n_jobs=-1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6132612982962498"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gbrt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200, 'max_features': 12, 'max_depth': 2}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gbrt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientDescentRegressor cross val score (default): [0.74336185 0.86523414 0.67868487 0.37091278 0.3051344 ]\n",
      "The mean score: 0.59\n"
     ]
    }
   ],
   "source": [
    "ada_boost_default_score = cross_val_score(AdaBoostRegressor(GradientBoostingRegressor()), X, y, cv=5, scoring='r2')\n",
    "print('GradientDescentRegressor cross val score (default): {}'.format(ada_boost_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(ada_boost_default_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_rf_default_score = cross_val_score(AdaBoostRegressor(GradientBoostingRegressor()), X, y, cv=5, scoring='r2')\n",
    "print('GradientDescentRegressor cross val score (default): {}'.format(ada_boost_default_score))\n",
    "print(\"The mean score: {:.2f}\".format(ada_boost_default_score.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
