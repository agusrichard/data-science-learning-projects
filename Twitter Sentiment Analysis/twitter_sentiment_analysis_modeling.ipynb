{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis_modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfQVdwcgvjTQpGOrixak8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agusrichard/data-science-projects/blob/master/Twitter%20Sentiment%20Analysis/twitter_sentiment_analysis_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EqBJGFaHj5r",
        "colab_type": "text"
      },
      "source": [
        "# Twitter Sentiment Analysis: Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xClBH37GxRj",
        "colab_type": "text"
      },
      "source": [
        "__Import Libraries__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkCytOc04vo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37617564-b65d-42a5-8953-f536671cfe54"
      },
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stvtHsNCJvve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "58bc7ac5-0b89-4c8b-be43-f9ad244de116"
      },
      "source": [
        "# Essentials\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import preprocessor as p\n",
        "from itertools import product\n",
        "from time import time\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette('colorblind')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myd80vHnHTr_",
        "colab_type": "text"
      },
      "source": [
        "__Load Dataset__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuBdDDYcJ6w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscmoGxwIlQQ",
        "colab_type": "text"
      },
      "source": [
        "__Helper Functions__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVg-mIMFInAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_predictions(model, filename='submission.csv'):\n",
        "    model.fit(train['tweet'], train['label'])\n",
        "    predictions = model.predict(test['tweet'])\n",
        "    predictions = pd.DataFrame(predictions, index=test['id'], columns=['label'])\n",
        "    predictions.to_csv(filename)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5-okbi9HVwI",
        "colab_type": "text"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz2qx1lPH3Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "31aa33e6-8597-43dc-9581-c47a10a81da2"
      },
      "source": [
        "pipeline = Pipeline([('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "                     ('classifier', MultinomialNB())])\n",
        "scoring = cross_val_score(pipeline, train['tweet'], train['label'], scoring='f1', cv=5, verbose=10, n_jobs=-1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.2s remaining:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ29xWnnJVdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58d660cb-247a-4ef0-f051-3beb01f85513"
      },
      "source": [
        "print('f-1 Score: ', scoring.mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f-1 Score:  0.25606393716690085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMpte8V8Jins",
        "colab_type": "text"
      },
      "source": [
        "## Modeling Exploration 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7JArUs1LjiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18e52865-0665-4e52-ab99-810287efe1a0"
      },
      "source": [
        "vectorizers = [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')]\n",
        "classifiers = [MultinomialNB(), ComplementNB(), KNeighborsClassifier(), LogisticRegression(), LinearSVC(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
        "\n",
        "results = {}\n",
        "for vectorizer, classifier in product(vectorizers, classifiers):\n",
        "    pipe = Pipeline([('vectorizer', vectorizer),\n",
        "                    ('classifier', classifier)])\n",
        "    print('=' * 100)\n",
        "    vect_name = str(type(vectorizer)).split('.')[-1][:-2]\n",
        "    clf_name = str(type(classifier)).split('.')[-1][:-2]\n",
        "    print(f\"{vect_name} <--> {clf_name}\".center(100))\n",
        "    score = cross_val_score(pipe, train['tweet'], train['label'], cv=5, scoring='f1', n_jobs=-1, verbose=10)\n",
        "    print('\\n\\n' + f\"f-1 score: {score.mean():}\")\n",
        "    print('-' * 100, '\\n\\n')\n",
        "\n",
        "    results[(vect_name, clf_name)] = score"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "                                 CountVectorizer <--> MultinomialNB                                 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6394493785033994\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 CountVectorizer <--> ComplementNB                                  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6374585362949438\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                             CountVectorizer <--> KNeighborsClassifier                              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.3s\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   15.8s remaining:   10.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.2728865300751167\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                              CountVectorizer <--> LogisticRegression                               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    5.4s remaining:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6402008558499283\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                   CountVectorizer <--> LinearSVC                                   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    4.1s remaining:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6944149915585776\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                            CountVectorizer <--> RandomForestClassifier                             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   41.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.4min remaining:   55.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6327768186390911\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                          CountVectorizer <--> GradientBoostingClassifier                           \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   17.3s remaining:   11.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.4251282721778117\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 TfidfVectorizer <--> MultinomialNB                                 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.25606393716690085\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 TfidfVectorizer <--> ComplementNB                                  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6212468372647727\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                             TfidfVectorizer <--> KNeighborsClassifier                              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   11.2s remaining:    7.4s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.2821360307378168\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                              TfidfVectorizer <--> LogisticRegression                               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.2s remaining:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.4396280463358592\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                   TfidfVectorizer <--> LinearSVC                                   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    2.1s remaining:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.7053205869032435\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                            TfidfVectorizer <--> RandomForestClassifier                             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   34.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.2min remaining:   46.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6225897954559982\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                          TfidfVectorizer <--> GradientBoostingClassifier                           \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   27.2s remaining:   18.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.4260457248016564\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImEAG9aLRduY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "e2755edf-94f9-46fe-e3ab-8ea17a07a9e9"
      },
      "source": [
        "for (vec_name, clf_name), score in results.items():\n",
        "    print(f\"{vec_name} {clf_name}\")\n",
        "    print(score)\n",
        "    print(f\"Mean: {score.mean()}\", '\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer MultinomialNB\n",
            "[0.6572238  0.62430939 0.65541491 0.62290503 0.63739377]\n",
            "Mean: 0.6394493785033994 \n",
            "\n",
            "CountVectorizer ComplementNB\n",
            "[0.6509636  0.625      0.64403292 0.63005181 0.63724435]\n",
            "Mean: 0.6374585362949438 \n",
            "\n",
            "CountVectorizer KNeighborsClassifier\n",
            "[0.28358209 0.2754717  0.28355388 0.23938224 0.28244275]\n",
            "Mean: 0.2728865300751167 \n",
            "\n",
            "CountVectorizer LogisticRegression\n",
            "[0.64367816 0.65289256 0.65541491 0.63955119 0.60946746]\n",
            "Mean: 0.6402008558499283 \n",
            "\n",
            "CountVectorizer LinearSVC\n",
            "[0.70166453 0.69693252 0.7075     0.68726823 0.67870968]\n",
            "Mean: 0.6944149915585776 \n",
            "\n",
            "CountVectorizer RandomForestClassifier\n",
            "[0.62721893 0.64689266 0.64825581 0.62590975 0.61560694]\n",
            "Mean: 0.6327768186390911 \n",
            "\n",
            "CountVectorizer GradientBoostingClassifier\n",
            "[0.4028021  0.45950413 0.44142615 0.42051282 0.40139616]\n",
            "Mean: 0.4251282721778117 \n",
            "\n",
            "TfidfVectorizer MultinomialNB\n",
            "[0.22879684 0.28897338 0.28680688 0.22574257 0.25      ]\n",
            "Mean: 0.25606393716690085 \n",
            "\n",
            "TfidfVectorizer ComplementNB\n",
            "[0.64118372 0.61594203 0.63106796 0.60340633 0.61463415]\n",
            "Mean: 0.6212468372647727 \n",
            "\n",
            "TfidfVectorizer KNeighborsClassifier\n",
            "[0.28787879 0.29867675 0.28571429 0.27586207 0.26254826]\n",
            "Mean: 0.2821360307378168 \n",
            "\n",
            "TfidfVectorizer LogisticRegression\n",
            "[0.42611684 0.47194719 0.47254576 0.40972222 0.41780822]\n",
            "Mean: 0.4396280463358592 \n",
            "\n",
            "TfidfVectorizer LinearSVC\n",
            "[0.70299728 0.70680628 0.7232376  0.70418848 0.6893733 ]\n",
            "Mean: 0.7053205869032435 \n",
            "\n",
            "TfidfVectorizer RandomForestClassifier\n",
            "[0.61976048 0.62682216 0.64534884 0.63543192 0.58558559]\n",
            "Mean: 0.6225897954559982 \n",
            "\n",
            "TfidfVectorizer GradientBoostingClassifier\n",
            "[0.41105354 0.45901639 0.44705882 0.40614334 0.40695652]\n",
            "Mean: 0.4260457248016564 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C7DBH2BU_-8",
        "colab_type": "text"
      },
      "source": [
        "Best model for the first exploration is LinearSVC with f1 score 0.7053"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_4iw9_JWN-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_pipe = Pipeline([('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "                      ('classifier', LinearSVC())])\n",
        "save_predictions(best_pipe)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7VQbKaZZvta",
        "colab_type": "text"
      },
      "source": [
        "## Modeling Exploration 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx_Gy5viFbJI",
        "colab_type": "text"
      },
      "source": [
        "In this section, we are using cleaned data. The models are still the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9zgc_Yj_x5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TweetCleaner(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        result = []\n",
        "        for text in X:\n",
        "            text = text.split()\n",
        "            text = [word.lower() for word in text]\n",
        "            text = [word.encode('ascii', 'ignore') for word in text]\n",
        "            text = [word.decode('utf-8') for word in text]\n",
        "            table = str.maketrans('', '', string.punctuation)\n",
        "            text = [word.translate(table) for word in text if word != '']\n",
        "\n",
        "            result.append(' '.join(text))\n",
        "\n",
        "        return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYvyYKFVFAUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "086465cc-745e-45b5-f45f-e7c23deb8ae2"
      },
      "source": [
        "vectorizers = [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')]\n",
        "classifiers = [MultinomialNB(), ComplementNB(), KNeighborsClassifier(), LogisticRegression(), LinearSVC(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
        "\n",
        "results = {}\n",
        "for vectorizer, classifier in product(vectorizers, classifiers):\n",
        "    pipe = Pipeline([('cleaner', TweetCleaner()),\n",
        "                     ('vectorizer', vectorizer),\n",
        "                     ('classifier', classifier)])\n",
        "    print('=' * 100)\n",
        "    vect_name = str(type(vectorizer)).split('.')[-1][:-2]\n",
        "    clf_name = str(type(classifier)).split('.')[-1][:-2]\n",
        "    print(f\"{vect_name} <--> {clf_name}\".center(100))\n",
        "    score = cross_val_score(pipe, train['tweet'], train['label'], cv=5, scoring='f1', n_jobs=-1, verbose=10)\n",
        "    print('\\n\\n' + f\"f-1 score: {score.mean():}\")\n",
        "    print('-' * 100, '\\n\\n')\n",
        "\n",
        "    results[(vect_name, clf_name)] = score"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "                                 CountVectorizer <--> MultinomialNB                                 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.8s remaining:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6313828276075008\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 CountVectorizer <--> ComplementNB                                  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.8s remaining:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6293515100403334\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                             CountVectorizer <--> KNeighborsClassifier                              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   13.7s remaining:    9.1s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   18.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   18.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.27379608086928986\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                              CountVectorizer <--> LogisticRegression                               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.0s remaining:    4.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6414021836065908\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                   CountVectorizer <--> LinearSVC                                   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.0s remaining:    4.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.693928323067196\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                            CountVectorizer <--> RandomForestClassifier                             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   41.7s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.4min remaining:   56.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6239049467448397\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                          CountVectorizer <--> GradientBoostingClassifier                           \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   19.3s remaining:   12.8s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.41959777081953725\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 TfidfVectorizer <--> MultinomialNB                                 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.9s remaining:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.26962728588062956\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 TfidfVectorizer <--> ComplementNB                                  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.9s remaining:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6092242467941131\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                             TfidfVectorizer <--> KNeighborsClassifier                              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   12.7s remaining:    8.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.26868687216474785\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                              TfidfVectorizer <--> LogisticRegression                               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    5.1s remaining:    3.4s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.4381882255526901\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                   TfidfVectorizer <--> LinearSVC                                   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    4.1s remaining:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.704728740893137\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                            TfidfVectorizer <--> RandomForestClassifier                             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   35.1s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.2min remaining:   47.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6283180875562894\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                          TfidfVectorizer <--> GradientBoostingClassifier                           \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   28.9s remaining:   19.3s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.42294227799452877\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   39.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   39.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-918h8KFm1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "f71201e9-4bc4-496f-c9f2-ca7e58378991"
      },
      "source": [
        "for (vec_name, clf_name), score in results.items():\n",
        "    print(f\"{vec_name} {clf_name}\")\n",
        "    print(score)\n",
        "    print(f\"Mean: {score.mean()}\", '\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer MultinomialNB\n",
            "[0.6504298  0.61218837 0.66201117 0.61645746 0.61582734]\n",
            "Mean: 0.6313828276075008 \n",
            "\n",
            "CountVectorizer ComplementNB\n",
            "[0.64247599 0.62061637 0.63485477 0.62474227 0.62406816]\n",
            "Mean: 0.6293515100403334 \n",
            "\n",
            "CountVectorizer KNeighborsClassifier\n",
            "[0.28465804 0.26768642 0.27809524 0.26254826 0.27599244]\n",
            "Mean: 0.27379608086928986 \n",
            "\n",
            "CountVectorizer LogisticRegression\n",
            "[0.6571835  0.6519337  0.65260197 0.64796634 0.59732541]\n",
            "Mean: 0.6414021836065908 \n",
            "\n",
            "CountVectorizer LinearSVC\n",
            "[0.70393901 0.69392813 0.69586984 0.69135802 0.68454662]\n",
            "Mean: 0.693928323067196 \n",
            "\n",
            "CountVectorizer RandomForestClassifier\n",
            "[0.61791045 0.6173913  0.63988522 0.6323319  0.61200586]\n",
            "Mean: 0.6239049467448397 \n",
            "\n",
            "CountVectorizer GradientBoostingClassifier\n",
            "[0.40421793 0.44705882 0.43361345 0.39930556 0.4137931 ]\n",
            "Mean: 0.41959777081953725 \n",
            "\n",
            "TfidfVectorizer MultinomialNB\n",
            "[0.25291829 0.29222011 0.29333333 0.23274162 0.27692308]\n",
            "Mean: 0.26962728588062956 \n",
            "\n",
            "TfidfVectorizer ComplementNB\n",
            "[0.62940462 0.60805861 0.61818182 0.59047619 0.6       ]\n",
            "Mean: 0.6092242467941131 \n",
            "\n",
            "TfidfVectorizer KNeighborsClassifier\n",
            "[0.26254826 0.27862595 0.28625954 0.25968992 0.25631068]\n",
            "Mean: 0.26868687216474785 \n",
            "\n",
            "TfidfVectorizer LogisticRegression\n",
            "[0.42413793 0.47603306 0.45561139 0.41247834 0.42268041]\n",
            "Mean: 0.4381882255526901 \n",
            "\n",
            "TfidfVectorizer LinearSVC\n",
            "[0.71195652 0.70773263 0.7191601  0.69908016 0.68571429]\n",
            "Mean: 0.704728740893137 \n",
            "\n",
            "TfidfVectorizer RandomForestClassifier\n",
            "[0.62668666 0.63386397 0.64139942 0.63492063 0.60471976]\n",
            "Mean: 0.6283180875562894 \n",
            "\n",
            "TfidfVectorizer GradientBoostingClassifier\n",
            "[0.40695652 0.45896147 0.43844857 0.41034483 0.4       ]\n",
            "Mean: 0.42294227799452877 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Io2FE2FaxH",
        "colab_type": "text"
      },
      "source": [
        "The best model on the second exploration is LinearSVC with score 0.7047. There is slightly decrease in score compared to the first exploration best model."
      ]
    }
  ]
}