{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis_modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEBZuh/82ICMNZ1oqi3Cl5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agusrichard/data-science-projects/blob/master/Twitter%20Sentiment%20Analysis/twitter_sentiment_analysis_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EqBJGFaHj5r",
        "colab_type": "text"
      },
      "source": [
        "# Twitter Sentiment Analysis: Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xClBH37GxRj",
        "colab_type": "text"
      },
      "source": [
        "__Import Libraries__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stvtHsNCJvve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Essentials\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from itertools import product\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette('colorblind')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myd80vHnHTr_",
        "colab_type": "text"
      },
      "source": [
        "__Load Dataset__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuBdDDYcJ6w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscmoGxwIlQQ",
        "colab_type": "text"
      },
      "source": [
        "__Helper Functions__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVg-mIMFInAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_predictions(model, filename='submission.csv'):\n",
        "    model.fit(train['tweet'], train['label'])\n",
        "    predictions = model.predict(test['tweet'])\n",
        "    predictions = pd.DataFrame(predictions, index=test['id'], columns=['label'])\n",
        "    predictions.to_csv(filename)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5-okbi9HVwI",
        "colab_type": "text"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz2qx1lPH3Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f0d36597-b021-481f-d520-84ec96b18bde"
      },
      "source": [
        "pipeline = Pipeline([('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "                     ('classifier', MultinomialNB())])\n",
        "scoring = cross_val_score(pipeline, train['tweet'], train['label'], scoring='f1', cv=5, verbose=10, n_jobs=-1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.3s remaining:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ29xWnnJVdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "717c85bd-480b-441d-b49e-e65b570418f2"
      },
      "source": [
        "print('f-1 Score: ', scoring.mean())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f-1 Score:  0.25606393716690085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMpte8V8Jins",
        "colab_type": "text"
      },
      "source": [
        "## Modeling Exploration 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7JArUs1LjiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3dd883b-b499-4f10-bf78-2db7eb9c9b9d"
      },
      "source": [
        "vectorizers = [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')]\n",
        "classifiers = [MultinomialNB(), ComplementNB(), KNeighborsClassifier(), LogisticRegression(), LinearSVC(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
        "\n",
        "results = {}\n",
        "for vectorizer, classifier in product(vectorizers, classifiers):\n",
        "    pipe = Pipeline([('vectorizer', vectorizer),\n",
        "                     ('classifier', classifier)])\n",
        "    print('=' * 100)\n",
        "    vect_name = str(type(vectorizer)).split('.')[-1][:-2]\n",
        "    clf_name = str(type(classifier)).split('.')[-1][:-2]\n",
        "    print(f\"{vect_name} <--> {clf_name}\".center(100))\n",
        "    score = cross_val_score(pipe, train['tweet'], train['label'], cv=5, scoring='f1', n_jobs=-1, verbose=10)\n",
        "    print('\\n\\n' + f\"f-1 score: {score.mean():}\")\n",
        "    print('-' * 100, '\\n\\n')\n",
        "\n",
        "    results[(vect_name, clf_name)] = score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "                                 CountVectorizer <--> MultinomialNB                                 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.8s remaining:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6394493785033994\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 CountVectorizer <--> ComplementNB                                  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6374585362949438\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                             CountVectorizer <--> KNeighborsClassifier                              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    8.1s\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   15.9s remaining:   10.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.2728865300751167\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                              CountVectorizer <--> LogisticRegression                               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    5.4s remaining:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6402008558499283\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                   CountVectorizer <--> LinearSVC                                   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.9s remaining:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6944149915585776\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                            CountVectorizer <--> RandomForestClassifier                             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   41.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.4min remaining:   55.8s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6298224642371796\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                          CountVectorizer <--> GradientBoostingClassifier                           \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    8.8s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   17.5s remaining:   11.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.42659062683664173\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 TfidfVectorizer <--> MultinomialNB                                 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.25606393716690085\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                 TfidfVectorizer <--> ComplementNB                                  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    2.0s remaining:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6212468372647727\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                             TfidfVectorizer <--> KNeighborsClassifier                              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   10.7s remaining:    7.1s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.2821360307378168\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                              TfidfVectorizer <--> LogisticRegression                               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.3s remaining:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.4396280463358592\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                   TfidfVectorizer <--> LinearSVC                                   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    2.1s remaining:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.7053205869032435\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                            TfidfVectorizer <--> RandomForestClassifier                             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   35.1s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.2min remaining:   47.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.6183242934301061\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                          TfidfVectorizer <--> GradientBoostingClassifier                           \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   27.0s remaining:   18.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "f-1 score: 0.4244721719952369\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImEAG9aLRduY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "8c16bbd4-467c-49a9-d3e1-cd1c62508527"
      },
      "source": [
        "for (vec_name, clf_name), score in results.items():\n",
        "    print(f\"{vec_name} {clf_name}\")\n",
        "    print(score)\n",
        "    print(f\"Mean: {score.mean()}\", '\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer MultinomialNB\n",
            "[0.6572238  0.62430939 0.65541491 0.62290503 0.63739377]\n",
            "Mean: 0.6394493785033994 \n",
            "\n",
            "CountVectorizer ComplementNB\n",
            "[0.6509636  0.625      0.64403292 0.63005181 0.63724435]\n",
            "Mean: 0.6374585362949438 \n",
            "\n",
            "CountVectorizer KNeighborsClassifier\n",
            "[0.28358209 0.2754717  0.28355388 0.23938224 0.28244275]\n",
            "Mean: 0.2728865300751167 \n",
            "\n",
            "CountVectorizer LogisticRegression\n",
            "[0.64367816 0.65289256 0.65541491 0.63955119 0.60946746]\n",
            "Mean: 0.6402008558499283 \n",
            "\n",
            "CountVectorizer LinearSVC\n",
            "[0.70166453 0.69693252 0.7075     0.68726823 0.67870968]\n",
            "Mean: 0.6944149915585776 \n",
            "\n",
            "CountVectorizer RandomForestClassifier\n",
            "[0.60986547 0.6344239  0.64841499 0.63701578 0.61939219]\n",
            "Mean: 0.6298224642371796 \n",
            "\n",
            "CountVectorizer GradientBoostingClassifier\n",
            "[0.41666667 0.45619835 0.43803056 0.41580756 0.40625   ]\n",
            "Mean: 0.42659062683664173 \n",
            "\n",
            "TfidfVectorizer MultinomialNB\n",
            "[0.22879684 0.28897338 0.28680688 0.22574257 0.25      ]\n",
            "Mean: 0.25606393716690085 \n",
            "\n",
            "TfidfVectorizer ComplementNB\n",
            "[0.64118372 0.61594203 0.63106796 0.60340633 0.61463415]\n",
            "Mean: 0.6212468372647727 \n",
            "\n",
            "TfidfVectorizer KNeighborsClassifier\n",
            "[0.28787879 0.29867675 0.28571429 0.27586207 0.26254826]\n",
            "Mean: 0.2821360307378168 \n",
            "\n",
            "TfidfVectorizer LogisticRegression\n",
            "[0.42611684 0.47194719 0.47254576 0.40972222 0.41780822]\n",
            "Mean: 0.4396280463358592 \n",
            "\n",
            "TfidfVectorizer LinearSVC\n",
            "[0.70299728 0.70680628 0.7232376  0.70418848 0.6893733 ]\n",
            "Mean: 0.7053205869032435 \n",
            "\n",
            "TfidfVectorizer RandomForestClassifier\n",
            "[0.58192956 0.64367816 0.64411765 0.63173217 0.59016393]\n",
            "Mean: 0.6183242934301061 \n",
            "\n",
            "TfidfVectorizer GradientBoostingClassifier\n",
            "[0.38947368 0.45544554 0.45742905 0.40753425 0.41247834]\n",
            "Mean: 0.4244721719952369 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C7DBH2BU_-8",
        "colab_type": "text"
      },
      "source": [
        "Best model for the first exploration is LinearSVC with f1 score 0.7053"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_4iw9_JWN-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_pipe = Pipeline([('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "                      ('classifier', LinearSVC())])\n",
        "save_predictions(best_pipe)"
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}